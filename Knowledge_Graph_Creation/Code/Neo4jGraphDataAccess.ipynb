{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the below packages.\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import textacy\n",
    "from textacy.extract import subject_verb_object_triples\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from py2neo import Database, Graph, Node, Relationship\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the input text:\n",
    "\n",
    "# Function returns the negation handled word if it is presend in the appos dictionary\n",
    "# Else returns the word itself\n",
    "def negationHandling(word):\n",
    "    if word in appos:\n",
    "        return appos[word]\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "# Check if a word is a Stopword\n",
    "# Stopword is a word that is commonly present in most of the documents and does not affect the model\n",
    "def isNotStopWord(word):\n",
    "    return word not in stopwords.words('english')\n",
    "\n",
    "\n",
    "def preprocessingText(text):\n",
    "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    #sentences = nltk.sent_tokenize(text)\n",
    "    tokens = []\n",
    "    temp = \"\"\n",
    "    \n",
    "    #for sentence in sentences:\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    #Converting to LowerCase\n",
    "    #words = map(str.lower, words)\n",
    "\n",
    "    # Remove stop words\n",
    "    words = filter(lambda x: isNotStopWord(x), words)\n",
    "\n",
    "    # Removing punctuations except '<.>/<?>/<!>'\n",
    "    punctuations = '\"#$%&\\'()*+,-/:;<=>@\\\\^_`{|}~'\n",
    "    words = map(lambda x: x.translate(str.maketrans('', '', punctuations)), words)\n",
    "\n",
    "    # Remove empty strings\n",
    "    words = filter(lambda x: len(x) > 0, words)\n",
    "\n",
    "    tokens = tokens + list(words)\n",
    "    temp = ' '.join(word for word in tokens)\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the entities and its type/annotations in a dictionary for using it in KG construction\n",
    "# Extract the SVO (Subject Verb Object) triples suing dependency parsing and save it in the svos list of tuples\n",
    "# Also save the labels of the SVO as a separate list\n",
    "\n",
    "def entity_svo_extract(text):\n",
    "    text = preprocessingText(text)\n",
    "    final_svos = []\n",
    "    final_text_svos = []\n",
    "    entity_dict = {}\n",
    "    svo_labels = []\n",
    "    #for i, text in enumerate(TEXTS):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        #print(f\"ent in doc.ents: {ent}\")\n",
    "        if ent not in entity_dict.keys():\n",
    "            #print(f\"ent: {ent}\")\n",
    "            entity_dict[str(ent)] = ent.label_ \n",
    "            #print(f\"ent label: {ent.label_}\")\n",
    "\n",
    "    svos = list(subject_verb_object_triples(doc))\n",
    "    #print(f\"svos: {svos}\")\n",
    "    svos_text = [(str(x[0]).strip(), str(x[1]).strip(), str(x[2]).strip()) for x in svos]\n",
    "    #print(f\"svos text: {svos_text}\")\n",
    "    final_svos = final_svos + svos\n",
    "    final_text_svos = final_text_svos + svos_text\n",
    "    print(f\"final text svos: {final_text_svos}\")\n",
    "\n",
    "    for svo in final_text_svos:\n",
    "        tup = ['Object', 'Object']\n",
    "        if(svo[0] in entity_dict.keys()):\n",
    "            tup[0] = entity_dict[svo[0]]\n",
    "\n",
    "        if(svo[2] in entity_dict.keys()):\n",
    "            tup[1] = entity_dict[svo[2]]\n",
    "        svo_labels.append(tuple(tup))\n",
    "        print(tup)\n",
    "    return svo_labels[0][0],final_text_svos[0][0],final_text_svos[0][1],svo_labels[0][1],final_text_svos[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def querry_graph(graph, f_node, f_name, rel, s_node, s_name):\n",
    "    query1 = '''\n",
    "        MATCH (f:{fnode})-[r:{rl}]-(m) \n",
    "        where f.name = '{fname}' \n",
    "        RETURN m\n",
    "    '''\n",
    "    query2 = '''\n",
    "        MATCH path = (n:{fnode})-[r]-(m)\n",
    "        where n.name = '{fname}'\n",
    "        RETURN path,r,m\n",
    "    '''\n",
    "    full_query = query2.format(fnode=f_node, fname=f_name, rl=rel)\n",
    "    nodes = graph.run(full_query)            \n",
    "    #names1 = [node['m']['name'] for node in nodes]\n",
    "    #print(names1)\n",
    "    names = [node['r'] for node in nodes]\n",
    "    print(f\"Based on your question probable answers are: {names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph = Graph(\"neo4j@bolt://localhost:7687\",password=\"1432\")\n",
    "def add_update_graph(graph, f_node, f_name, rel, s_node, s_name):\n",
    "    query = '''\n",
    "        MERGE (f:{fnode})-[r:{rl}]-(s:{snode})\n",
    "        ON CREATE SET f.name='{fname}' \n",
    "        ON CREATE SET s.name='{sname}'\n",
    "        RETURN f,r,s\n",
    "    '''\n",
    "    full_query = query.format(fnode=f_node, fname=f_name, rl=rel, snode=s_node, sname=s_name)\n",
    "    nodes = graph.run(full_query)            \n",
    "    names = [node['r'] for node in nodes]\n",
    "    print(f\"Your answer is updated in database as: {names}\")\n",
    "    #print(\"Your answer is updated\")\n",
    "#user_input = input(\"Please enter your input: \")\n",
    "#f_node, f_name, rel, s_node, s_name = entity_svo_extract(user_input)\n",
    "#add_update_graph(graph, f_node, f_name, rel, s_node, s_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the question: How petroleum extraction is distributed in India?\n",
      "final text svos: [('petroleum extraction', 'distributed', 'India')]\n",
      "['Object', 'GPE']\n",
      "Based on your question probable answers are: []\n",
      "Hope you are sattisfied with the answer, Help to choose options below\n",
      "Are you sattisfied with the answer? y/n : n\n",
      "Do you want to update the answer? y/n : y\n",
      "Please enter your input: petroleum extraction is unevenly distributed in India\n",
      "final text svos: [('petroleum extraction', 'distributed', 'India')]\n",
      "['Object', 'GPE']\n",
      "Knowledge Graph will be added/updated with below input:\n",
      "f_node:Object fn_name:petroleum extraction relation:distributed s_node:GPE sn_name:India\n",
      "Please enter 'y' for your final confirmation: y\n",
      "Your answer is updated in database as: [(oil production)-[:distributed {}]->(Alaska)]\n"
     ]
    }
   ],
   "source": [
    "#Connect to the graph\n",
    "graph = Graph(\"neo4j@bolt://localhost:7687\",password=\"1432\")\n",
    "#Getting question from the user\n",
    "question = input(\"Please enter the question: \")\n",
    "#How hydrogen bonds show features\n",
    "#oil production has fallen in Alaska\n",
    "#How oil production is distributed in Alaska\n",
    "f_node, f_name, rel, s_node, s_name = entity_svo_extract(question)\n",
    "querry_graph(graph, f_node, f_name, rel, s_node, s_name)\n",
    "print(\"Hope you are sattisfied with the answer, Help to choose options below\")\n",
    "option1 = input(\"Are you sattisfied with the answer? y/n : \")\n",
    "if option1 != 'y':\n",
    "    option2 = input(\"Do you want to update the answer? y/n : \")\n",
    "    if option2 == 'y':\n",
    "        user_input = input(\"Please enter your input: \")\n",
    "        f_node, f_name, rel, s_node, s_name = entity_svo_extract(user_input)\n",
    "        print(\"Knowledge Graph will be added/updated with below input:\")\n",
    "        print(f\"f_node:{f_node} fn_name:{f_name} relation:{rel} s_node:{s_node} sn_name:{s_name}\")\n",
    "        option3 = input(\"Please enter 'y' for your final confirmation: \")\n",
    "        if option3 == 'y':\n",
    "            add_update_graph(graph, f_node, f_name, rel, s_node, s_name)\n",
    "        else:\n",
    "            print(\"You have opted not to add/update answer suggested by you, Thanks for visiting\")\n",
    "    else:\n",
    "        print(\"Thanks for your feedback, will work to improve the system\")\n",
    "else:\n",
    "    print(\"Thanks for visiting the page, Hope you enjoyed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
